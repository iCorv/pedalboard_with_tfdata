{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# High Perfromance Audio Preprocessing with tf.data and pedalboard"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import typing\n",
    "from typing import Callable\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import time\n",
    "from IPython.display import Audio\n",
    "import json\n",
    "import tensorflow_datasets as tfds\n",
    "import tensorflow as tf\n",
    "import soxbindings as sox\n",
    "import pedalboard as pb\n",
    "from pedalboard import Pedalboard\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "SR = 22050\n",
    "MAXVAL = 32767\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "# make pretty plots\n",
    "plt.style.use('ggplot')\n",
    "mpl.rc('axes', labelsize=8)\n",
    "mpl.rc('xtick', labelsize=8)\n",
    "mpl.rc('ytick', labelsize=8)\n",
    "mpl.rc('axes', titlepad=20)\n",
    "mpl.rc('axes', titlesize=10)\n",
    "mpl.rc('axes', titleweight='normal')\n",
    "mpl.rc('legend', fontsize=8)\n",
    "mpl.rcParams['figure.dpi']= 300\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Download LJ Speech dataset and extract only the audio data."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "dataset, info = tfds.load(\n",
    "  'ljspeech', split='train',\n",
    "  download=True, with_info=True)\n",
    "\n",
    "# transform int16 audio to float32 in [-1, 1]\n",
    "dataset = dataset.map(\n",
    "    lambda example_dict: tf.cast(example_dict['speech'], tf.float32) / MAXVAL,\n",
    "    num_parallel_calls=AUTOTUNE)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Define Sox function for effect preprocessing. We use the library soxbindings since it \"works\" in multithreading environments, like tf.data, in that it doesn't fail, but it doesn't let you actually use multi-threading"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "sox_effects = {\n",
    "    'compand': {},\n",
    "    'chorus': {},\n",
    "    'highpass': {'frequency': 100},\n",
    "    'lowpass': {'frequency': 8000},\n",
    "    'phaser': {},\n",
    "    'reverb': {}\n",
    "}\n",
    "\n",
    "def get_sox_effect(\n",
    "    effect_type: str,\n",
    "    effect_params: dict\n",
    "    ) -> Callable[[tf.Tensor], np.ndarray]:\n",
    "    # this allows multi-threading envs\n",
    "    @sox.sox_context()\n",
    "    def sox_effect(y: tf.Tensor) -> np.ndarray:\n",
    "        y = y.numpy()\n",
    "        tfm = sox.Transformer()\n",
    "        getattr(tfm, effect_type)(**effect_params)\n",
    "        y_out = tfm.build_array(input_array=y, sample_rate_in=SR)\n",
    "        return y_out\n",
    "    return sox_effect\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "sox_results = dict()\n",
    "for effect, params in sox_effects.items():\n",
    "    # define pipeline for this effect\n",
    "    sox_dataset = dataset.map(\n",
    "        lambda speech: tf.py_function(\n",
    "            get_sox_effect(effect, params),\n",
    "            [speech],\n",
    "            tf.float32)\n",
    "    )\n",
    "    t = time.time()\n",
    "    # apply effect to each example\n",
    "    for elem in sox_dataset:\n",
    "        pass\n",
    "    elapsed_time = time.time() - t\n",
    "    sox_results[effect] = elapsed_time\n",
    "    print(f'{effect}: {elapsed_time:.2f}s')\n",
    "\n",
    "json.dump(sox_results, open('./sox_results.json', 'w'))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "pedalboard_effects = [\n",
    "    'Compressor',\n",
    "    'Chorus',\n",
    "    'HighpassFilter',\n",
    "    'LowpassFilter',\n",
    "    'Phaser',\n",
    "    'Reverb'\n",
    "]\n",
    "\n",
    "def get_pb_effect(\n",
    "    effect_type: str\n",
    "    ) -> Callable[[tf.Tensor], np.ndarray]:\n",
    "    def pb_effect(y: tf.Tensor) -> np.ndarray:\n",
    "        y = y.numpy()\n",
    "        effect = getattr(pb, effect_type)()\n",
    "        y_out = effect(y, sample_rate=SR)\n",
    "        return y_out\n",
    "    return pb_effect"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "pb_results = dict()\n",
    "for effect in pedalboard_effects:\n",
    "    # define pipeline for this effect\n",
    "    pb_dataset = dataset.map(\n",
    "        lambda speech: tf.py_function(\n",
    "            get_pb_effect(effect),\n",
    "            [speech],\n",
    "            tf.float32),\n",
    "        num_parallel_calls=AUTOTUNE\n",
    "    )\n",
    "    t = time.time()\n",
    "    # apply effect to each example\n",
    "    for elem in pb_dataset:\n",
    "        pass\n",
    "    elapsed_time = time.time() - t\n",
    "    pb_results[effect] = elapsed_time\n",
    "    print(f'{effect}: {elapsed_time:.2f}s')\n",
    "\n",
    "json.dump(pb_results, open('./pedalboard_results.json', 'w'))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "pb_results = json.load(open('./pedalboard_results.json', 'r'))\n",
    "sox_results = json.load(open('./sox_results.json', 'r'))\n",
    "labels = pedalboard_effects\n",
    "pb_times = [value for _, value in pb_results.items()]\n",
    "sox_times = [value for _, value in sox_results.items()]\n",
    "\n",
    "x = np.arange(len(labels))  # the label locations\n",
    "width = 0.35  # the width of the bars\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "rects2 = ax.bar(x + width/2, sox_times, width, label='SoxBindings')\n",
    "rects1 = ax.bar(x - width/2, pb_times, width, label='Pedalboard')\n",
    "\n",
    "ax.set_ylabel('duration in s')\n",
    "ax.set_title('Transform LJ Speech with one Effect')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(labels, rotation=50)\n",
    "ax.legend()\n",
    "\n",
    "ax.bar_label(rects1, padding=3, fmt='%.1f', fontsize=8)\n",
    "ax.bar_label(rects2, padding=3, fmt='%.1f', fontsize=8)\n",
    "\n",
    "fig.tight_layout()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Transform the LJ Speech Dataset with a Signal Chain"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# sox effect chain\n",
    "\n",
    "def get_sox_effect_chain() -> Callable[[tf.Tensor], np.ndarray]:\n",
    "    tfm = sox.Transformer()\n",
    "    for effect_type, effect_params in sox_effects.items():\n",
    "        getattr(tfm, effect_type)(**effect_params)\n",
    "    @sox.sox_context()\n",
    "    def sox_effect(y: tf.Tensor) -> np.ndarray:\n",
    "        y = y.numpy()\n",
    "        y_out = tfm.build_array(input_array=y, sample_rate_in=SR)\n",
    "        return y_out\n",
    "    return sox_effect\n",
    "\n",
    "sox_results = dict()\n",
    "# define pipeline for this effect\n",
    "sox_dataset = dataset.map(\n",
    "    lambda speech: tf.py_function(\n",
    "        get_sox_effect_chain(),\n",
    "        [speech],\n",
    "        tf.float32)\n",
    ")\n",
    "t = time.time()\n",
    "# apply effect to each example\n",
    "for elem in sox_dataset:\n",
    "    pass\n",
    "elapsed_time = time.time() - t\n",
    "sox_results['sox_effect_chain'] = elapsed_time\n",
    "print(f'Sox Effect Chain: {elapsed_time:.2f}s')\n",
    "\n",
    "json.dump(sox_results, open('./sox_results_chain.json', 'w'))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# pedalboard effect chain\n",
    "\n",
    "def get_pb_effect_chain() -> Callable[[tf.Tensor], np.ndarray]:\n",
    "    board = Pedalboard(\n",
    "        [getattr(pb, effect_type)() for effect_type in pedalboard_effects],\n",
    "        sample_rate=SR)\n",
    "    def pb_effect(y: tf.Tensor) -> np.ndarray:\n",
    "        y = y.numpy()\n",
    "        y_out = board(y)\n",
    "        return y_out\n",
    "    return pb_effect\n",
    "\n",
    "pb_results = dict()\n",
    "# define pipeline for this effect\n",
    "pb_dataset = dataset.map(\n",
    "    lambda speech: tf.py_function(\n",
    "        get_pb_effect_chain(),\n",
    "        [speech],\n",
    "        tf.float32),\n",
    "    num_parallel_calls=AUTOTUNE\n",
    ")\n",
    "t = time.time()\n",
    "# apply effect to each example\n",
    "for elem in pb_dataset:\n",
    "    pass\n",
    "elapsed_time = time.time() - t\n",
    "pb_results['pedalboard_effect_chain'] = elapsed_time\n",
    "print(f'Pedalboard Effect Chain: {elapsed_time:.2f}s')\n",
    "\n",
    "json.dump(pb_results, open('./pedalboard_results_chain.json', 'w'))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# pedalboard tf.data effect chain\n",
    "\n",
    "pb_results = dict()\n",
    "pb_dataset = dataset\n",
    "for effect in pedalboard_effects:\n",
    "    # define pipeline for this effect\n",
    "    pb_dataset = pb_dataset.map(\n",
    "        lambda speech: tf.py_function(\n",
    "            get_pb_effect(effect),\n",
    "            [speech],\n",
    "            tf.float32),\n",
    "        num_parallel_calls=AUTOTUNE\n",
    "    )\n",
    "t = time.time()\n",
    "# apply effect to each example\n",
    "for elem in pb_dataset:\n",
    "    pass\n",
    "elapsed_time = time.time() - t\n",
    "pb_results['pedalboard_effect_chain'] = elapsed_time\n",
    "print(f'Pedalboard Effect Chain: {elapsed_time:.2f}s')\n",
    "\n",
    "json.dump(pb_results, open('./pedalboard_results_tfdata_chain.json', 'w'))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "pb_chain = json.load(open('pedalboard_results_chain.json', 'r'))\n",
    "sox_chain = json.load(open('sox_results_chain.json', 'r'))\n",
    "pb_tfdata_chain = json.load(open('pedalboard_results_tfdata_chain.json', 'r'))\n",
    "labels = ['Pedalboard Chain', 'SoxBindings Chain', 'Pedalboard Chain w/ tf.data']\n",
    "\n",
    "x = [0., 0.5, 1.]  # the label locations\n",
    "width = 0.35  # the width of the bars\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "rects1 = ax.bar(x[0], pb_chain['pedalboard_effect_chain'], width, label=labels[0])\n",
    "rects2 = ax.bar(x[1], sox_chain['sox_effect_chain'], width, label=labels[1])\n",
    "rects3 = ax.bar(x[2], pb_tfdata_chain['pedalboard_effect_chain'], width, label=labels[2])\n",
    "\n",
    "ax.set_ylabel('duration in s')\n",
    "ax.set_title('Transform LJ Speech with Effect Chain')\n",
    "plt.tick_params(\n",
    "    axis='x',          \n",
    "    which='both',      \n",
    "    bottom=False,      \n",
    "    top=False,         \n",
    "    labelbottom=False)\n",
    "ax.legend()\n",
    "\n",
    "ax.bar_label(rects1, padding=3, fmt='%.1f', fontsize=8)\n",
    "ax.bar_label(rects2, padding=3, fmt='%.1f', fontsize=8)\n",
    "ax.bar_label(rects3, padding=3, fmt='%.1f', fontsize=8)\n",
    "\n",
    "fig.tight_layout()"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.11",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.11 64-bit ('stuff': conda)"
  },
  "interpreter": {
   "hash": "4470c832c40c2b79c3239b2bd45dc8f63a88f977d46bad5336380f3e4387bc07"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}